{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'network_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a4523e35f452>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnetwork_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0maux_functions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'network_model'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import argparse\n",
    "from network_model import model\n",
    "from aux_functions import *\n",
    "\n",
    "# Suppress TF warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "mouse_pts = []\n",
    "\n",
    "\n",
    "def get_mouse_points(event, x, y, flags, param):\n",
    "    # Used to mark 4 points on the frame zero of the video that will be warped\n",
    "    # Used to mark 2 points on the frame zero of the video that are 6 feet away\n",
    "    global mouseX, mouseY, mouse_pts\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        mouseX, mouseY = x, y\n",
    "        cv2.circle(image, (x, y), 10, (0, 255, 255), 10)\n",
    "        if \"mouse_pts\" not in globals():\n",
    "            mouse_pts = []\n",
    "        mouse_pts.append((x, y))\n",
    "        print(\"Point detected\")\n",
    "        print(mouse_pts)\n",
    "\n",
    "\n",
    "# Command-line input setup\n",
    "parser = argparse.ArgumentParser(description=\"SocialDistancing\")\n",
    "parser.add_argument(\n",
    "    \"--videopath\", type=str, default=\"vid_short.mp4\", help=\"Path to the video file\"\n",
    ")\n",
    "args = parser.parse_args()\n",
    "\n",
    "input_video = args.videopath\n",
    "\n",
    "# Define a DNN model\n",
    "DNN = model()\n",
    "# Get video handle\n",
    "cap = cv2.VideoCapture(input_video)\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "scale_w = 1.2 / 2\n",
    "scale_h = 4 / 2\n",
    "\n",
    "SOLID_BACK_COLOR = (41, 41, 41)\n",
    "# Setuo video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "output_movie = cv2.VideoWriter(\"Pedestrian_detect.avi\", fourcc, fps, (width, height))\n",
    "bird_movie = cv2.VideoWriter(\n",
    "    \"Pedestrian_bird.avi\", fourcc, fps, (int(width * scale_w), int(height * scale_h))\n",
    ")\n",
    "# Initialize necessary variables\n",
    "frame_num = 0\n",
    "total_pedestrians_detected = 0\n",
    "total_six_feet_violations = 0\n",
    "total_pairs = 0\n",
    "abs_six_feet_violations = 0\n",
    "pedestrian_per_sec = 0\n",
    "sh_index = 1\n",
    "sc_index = 1\n",
    "\n",
    "cv2.namedWindow(\"image\")\n",
    "cv2.setMouseCallback(\"image\", get_mouse_points)\n",
    "num_mouse_points = 0\n",
    "first_frame_display = True\n",
    "\n",
    "# Process each frame, until end of video\n",
    "while cap.isOpened():\n",
    "    frame_num += 1\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"end of the video file...\")\n",
    "        break\n",
    "\n",
    "    frame_h = frame.shape[0]\n",
    "    frame_w = frame.shape[1]\n",
    "\n",
    "    if frame_num == 1:\n",
    "        # Ask user to mark parallel points and two points 6 feet apart. Order bl, br, tr, tl, p1, p2\n",
    "        while True:\n",
    "            image = frame\n",
    "            cv2.imshow(\"image\", image)\n",
    "            cv2.waitKey(1)\n",
    "            if len(mouse_pts) == 7:\n",
    "                cv2.destroyWindow(\"image\")\n",
    "                break\n",
    "            first_frame_display = False\n",
    "        four_points = mouse_pts\n",
    "\n",
    "        # Get perspective\n",
    "        M, Minv = get_camera_perspective(frame, four_points[0:4])\n",
    "        pts = src = np.float32(np.array([four_points[4:]]))\n",
    "        warped_pt = cv2.perspectiveTransform(pts, M)[0]\n",
    "        d_thresh = np.sqrt(\n",
    "            (warped_pt[0][0] - warped_pt[1][0]) ** 2\n",
    "            + (warped_pt[0][1] - warped_pt[1][1]) ** 2\n",
    "        )\n",
    "        bird_image = np.zeros(\n",
    "            (int(frame_h * scale_h), int(frame_w * scale_w), 3), np.uint8\n",
    "        )\n",
    "\n",
    "        bird_image[:] = SOLID_BACK_COLOR\n",
    "        pedestrian_detect = frame\n",
    "\n",
    "    print(\"Processing frame: \", frame_num)\n",
    "\n",
    "    # draw polygon of ROI\n",
    "    pts = np.array(\n",
    "        [four_points[0], four_points[1], four_points[3], four_points[2]], np.int32\n",
    "    )\n",
    "    cv2.polylines(frame, [pts], True, (0, 255, 255), thickness=4)\n",
    "\n",
    "    # Detect person and bounding boxes using DNN\n",
    "    pedestrian_boxes, num_pedestrians = DNN.detect_pedestrians(frame)\n",
    "\n",
    "    if len(pedestrian_boxes) > 0:\n",
    "        pedestrian_detect = plot_pedestrian_boxes_on_image(frame, pedestrian_boxes)\n",
    "        warped_pts, bird_image = plot_points_on_bird_eye_view(\n",
    "            frame, pedestrian_boxes, M, scale_w, scale_h\n",
    "        )\n",
    "        six_feet_violations, ten_feet_violations, pairs = plot_lines_between_nodes(\n",
    "            warped_pts, bird_image, d_thresh\n",
    "        )\n",
    "        # plot_violation_rectangles(pedestrian_boxes, )\n",
    "        total_pedestrians_detected += num_pedestrians\n",
    "        total_pairs += pairs\n",
    "\n",
    "        total_six_feet_violations += six_feet_violations / fps\n",
    "        abs_six_feet_violations += six_feet_violations\n",
    "        pedestrian_per_sec, sh_index = calculate_stay_at_home_index(\n",
    "            total_pedestrians_detected, frame_num, fps\n",
    "        )\n",
    "\n",
    "    last_h = 75\n",
    "    text = \"# 6ft violations: \" + str(int(total_six_feet_violations))\n",
    "    pedestrian_detect, last_h = put_text(pedestrian_detect, text, text_offset_y=last_h)\n",
    "\n",
    "    text = \"Stay-at-home Index: \" + str(np.round(100 * sh_index, 1)) + \"%\"\n",
    "    pedestrian_detect, last_h = put_text(pedestrian_detect, text, text_offset_y=last_h)\n",
    "\n",
    "    if total_pairs != 0:\n",
    "        sc_index = 1 - abs_six_feet_violations / total_pairs\n",
    "\n",
    "    text = \"Social-distancing Index: \" + str(np.round(100 * sc_index, 1)) + \"%\"\n",
    "    pedestrian_detect, last_h = put_text(pedestrian_detect, text, text_offset_y=last_h)\n",
    "\n",
    "    cv2.imshow(\"Street Cam\", pedestrian_detect)\n",
    "    cv2.waitKey(1)\n",
    "    output_movie.write(pedestrian_detect)\n",
    "    bird_movie.write(bird_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Const_8:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'Const_9:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'Mul_4:0' shape=(4,) dtype=int32>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.constant([1,2,3,4])\n",
    "x2 = tf.constant([5,6,7,8])\n",
    "\n",
    "# Multiply\n",
    "result = tf.multiply(x1, x2)\n",
    "\n",
    "# Print the result\n",
    "x1,x2,result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
